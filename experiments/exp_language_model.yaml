# ===============================================
#   CRSD Large-Scale Configuration
#   For 100â€“500 MB text or sequential datasets
# ===============================================

model:
  # ðŸ”¸ Larger hidden & memory dimensions
  d_x: 128             # embedding dimension
  d_h: 256             # hidden dimension for CRSDCell
  res_dims: [64, 64, 64]  # more reservoir layers for richer dynamics
  d_k: 64              # key dimension for memory
  d_v: 64              # value dimension for memory
  mem_slots: 256       # larger episodic buffer to store longer history

train:
  batch_size: 4        # keep small if GPU memory is limited
  lr: 0.0003           # smaller LR for stable long training
  epochs: 5            # 5 full passes are usually enough for large data
  grad_clip: 1.0       # gradient clipping for stability
  checkpoint_every: 1  # save model checkpoint every epoch

data:
  # ðŸ”¸ Larger sequence and optional dataset path
  dataset_path: "data/enwik8_10M.txt"   # or your own large dataset file
  max_len: 512                      # sequence length per sample
  num_workers: 4                    # parallel data loading
